{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 3022: Intro to Data Science - Fall 2021 Final Coding Exam\n",
    "***\n",
    "\n",
    "This practicum is due on Canvas by Thursday, December 9, at **6:00 PM**. No late work is accepted. Your solutions to theoretical questions should be done in Markdown directly below the associated question.  Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  \n",
    "\n",
    "**Here are the rules:** \n",
    "\n",
    "1. All work, code and analysis, must be your own. \n",
    "1. You may use your course notes, posted lecture slides, textbooks, in-class notebooks, and homework solutions as resources.  You may also search online for answers to general knowledge questions like the form of a probability distribution function or how to perform a particular operation in Python/Pandas. \n",
    "1. This is meant to be like a coding portion of your midterm exam. So, the instructional team will be much less helpful than we typically are with homework. For example, we will not check answers, help debug your code, and so on.\n",
    "1. If something is left open-ended, it is because we want to see how you approach the kinds of problems you will encounter in the wild, where it will not always be clear what sort of tests/methods should be applied. Feel free to ask clarifying questions though.\n",
    "2. You may **NOT** post to message boards or other online resources asking for help.\n",
    "3. You may **NOT** copy-paste solutions *from anywhere*.\n",
    "4. You may **NOT** collaborate with classmates or anyone else.\n",
    "5. In short, **your work must be your own**. It really is that simple.\n",
    "\n",
    "Violation of the above rules will result in an immediate academic sanction (*at the very least*, you will receive a 0 on this practicum or an F in the course, depending on severity), and a trip to the Honor Code Council.\n",
    "\n",
    "**By submitting this assignment, you agree to abide by the rules given above.**\n",
    "\n",
    "***\n",
    "\n",
    "**Name**: Felipe Lima\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Late work is not accepted. Therefore, do not try to turn in work at the last minute as slow WiFi or computer crashing are not valid reasons for accepting late work. \n",
    "- If you have a question for us, post it as a **PRIVATE** message on Piazza.  If we decide that the question is appropriate for the entire class, then we will add it to a Practicum clarifications thread. \n",
    "- Do **NOT** load or use any Python packages that are not available in Anaconda 3.6. \n",
    "- Some problems with code may be autograded.  If we provide a function API **do not** change it.  If we do not provide a function API then you're free to structure your code however you like. \n",
    "- Submit only this Jupyter notebook to Canvas.  Do not compress it using tar, rar, zip, etc. If your work cannot be downloaded, opened, or interpreted by the grader then it will not be accepted at a later time.\n",
    "- This should go without saying, but... For any question that asks you to calculate something, you **must show all work to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from math import isnan\n",
    "import numpy as np \n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Problem 1 - Multiple Linear Regression\n",
    "\n",
    "We will further examine the `boxing$.csv` dataset in this problem.\n",
    "Ten professional boxers recieved a payday (in thousands) for their latest fight. How does the amount of money spent on trainers/coaches, the amount of money spent on promotion, and the amount of money recieved from sponsors relate to the amount of money made for their payday fight?\n",
    "\n",
    "---\n",
    "\n",
    "**Response**:\n",
    "- `Y` - amount of money made in boxing match (payday)\n",
    "\n",
    "**Features**:\n",
    "- `X1` - amount of money spent on trainers and coaches\n",
    "- `X2` - amount of money spent on promotion\n",
    "- `X3` - amount of money recieved from sponsors\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Read the data from the csv into a Pandas DataFrame.  Print the full dataframe to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85.099998</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>4.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.300003</td>\n",
       "      <td>12.9</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>8.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.200001</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>15.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130.600006</td>\n",
       "      <td>10.7</td>\n",
       "      <td>8.399999</td>\n",
       "      <td>12.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54.799999</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>10.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.299999</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>79.400002</td>\n",
       "      <td>9.2</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>9.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>91.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>135.399994</td>\n",
       "      <td>15.1</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>20.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>89.300003</td>\n",
       "      <td>10.2</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>7.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Y    X1        X2         X3\n",
       "0   85.099998   8.5  5.100000   4.700000\n",
       "1  106.300003  12.9  5.800000   8.800000\n",
       "2   50.200001   5.2  2.100000  15.100000\n",
       "3  130.600006  10.7  8.399999  12.200000\n",
       "4   54.799999   3.1  2.900000  10.600000\n",
       "5   30.299999   3.5  1.200000   3.500000\n",
       "6   79.400002   9.2  3.700000   9.700000\n",
       "7   91.000000   9.0  7.600000   5.900000\n",
       "8  135.399994  15.1  7.700000  20.799999\n",
       "9   89.300003  10.2  4.500000   7.900000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code Here\n",
    "file_path = 'boxing$.csv'\n",
    "dfBo = pd.read_csv(file_path)\n",
    "\n",
    "dfBo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B:** Now, let's fit a multiple linear regression model! We will use the statsmodels package for this task. Execute the following cell to import the required package. Then answer to following questions/perform the requested tasks. \n",
    "\n",
    "- Use sm.OLS.fit to accomplish this. \n",
    "\n",
    "- Then use model.params to print the regression coeficients to the screen.\n",
    "\n",
    "- Use a Markdown cell to specify the MLR model in the form: $ \\hat{y} = \\beta_0+\\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const    7.676029\n",
      "X1       3.661604\n",
      "X2       7.621051\n",
      "X3       0.828468\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Code Here\n",
    "X = dfBo[[\"X1\", \"X2\", \"X3\"]]\n",
    "X = sm.add_constant(X)\n",
    "y = dfBo[\"Y\"]\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "print(model.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "$$\n",
    "\\texttt{Y} = 7.676029 + 3.661604 \\times \\texttt{X1} + 7.621051 \\times \\texttt{X2} + 0.828468 \\times \\texttt{X3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Inspect the output from your MLR model from **Part B**. Perform the appropriate statistical hypothesis test at the $\\alpha = 0.01$ significance level to determine if _at least one_ of the features is related to the the response $y$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felipelima/opt/anaconda3/lib/python3.8/site-packages/scipy/stats/stats.py:1603: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   58.22</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 09 Dec 2021</td> <th>  Prob (F-statistic):</th> <td>7.91e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:47:41</td>     <th>  Log-Likelihood:    </th> <td> -31.839</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    10</td>      <th>  AIC:               </th> <td>   71.68</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     6</td>      <th>  BIC:               </th> <td>   72.89</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    7.6760</td> <td>    6.760</td> <td>    1.135</td> <td> 0.299</td> <td>   -8.866</td> <td>   24.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>    <td>    3.6616</td> <td>    1.118</td> <td>    3.276</td> <td> 0.017</td> <td>    0.927</td> <td>    6.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>    <td>    7.6211</td> <td>    1.657</td> <td>    4.598</td> <td> 0.004</td> <td>    3.566</td> <td>   11.676</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X3</th>    <td>    0.8285</td> <td>    0.539</td> <td>    1.536</td> <td> 0.175</td> <td>   -0.491</td> <td>    2.148</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.444</td> <th>  Durbin-Watson:     </th> <td>   1.971</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.486</td> <th>  Jarque-Bera (JB):  </th> <td>   0.427</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.505</td> <th>  Prob(JB):          </th> <td>   0.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.937</td> <th>  Cond. No.          </th> <td>    43.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.967\n",
       "Model:                            OLS   Adj. R-squared:                  0.950\n",
       "Method:                 Least Squares   F-statistic:                     58.22\n",
       "Date:                Thu, 09 Dec 2021   Prob (F-statistic):           7.91e-05\n",
       "Time:                        21:47:41   Log-Likelihood:                -31.839\n",
       "No. Observations:                  10   AIC:                             71.68\n",
       "Df Residuals:                       6   BIC:                             72.89\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          7.6760      6.760      1.135      0.299      -8.866      24.218\n",
       "X1             3.6616      1.118      3.276      0.017       0.927       6.397\n",
       "X2             7.6211      1.657      4.598      0.004       3.566      11.676\n",
       "X3             0.8285      0.539      1.536      0.175      -0.491       2.148\n",
       "==============================================================================\n",
       "Omnibus:                        1.444   Durbin-Watson:                   1.971\n",
       "Prob(Omnibus):                  0.486   Jarque-Bera (JB):                0.427\n",
       "Skew:                          -0.505   Prob(JB):                        0.808\n",
       "Kurtosis:                       2.937   Cond. No.                         43.0\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code Here\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "One of the features is related to y and that is X2: the amount of money spent on promotion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D:** Using the statsmodels output from **Part C**, indicate in the table below, which features seem to have a significant relationship with the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature Name | Significant Relationshiip w/ Response (Yes or No) | Reason (one or two word explanation) |\n",
    "| --- | --- | --- |\n",
    "| X1 | No | (The computed p-values associated with $X_1$ is above the $\\alpha = 0.01$ significance level.) |\n",
    "| X2 | Yes | (The computed p-values associated with $X_2$ is below the $\\alpha = 0.01$ significance level. |\n",
    "| X3 | No | (The computed p-values associated with $X_3$ is above the $\\alpha = 0.01$ significance level.) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: Forward selection is the process of fitting an MLR model by adding one feature to the model at a time. There are multiple ways to decide which features are added. We will use the Sum of Squared Errors (SSE) to select our features. The full model in this problem involves 3 features. We seek to build a \"reduced model\" with the two \"best\" features.\n",
    "\n",
    "How is a forward selection carried out? Read on for a detailed description of the process.\n",
    "\n",
    "- Write a function `forward_select(df, resp_str, maxk)` that takes in the DataFrame, the name of the column corresponding to the response, and the maximum number of desired features, and returns a list of feature names corresponding to the `maxk` most important features via forward selection.   \n",
    "\n",
    "- At each stage in forward selection you should add the feature whose inclusion in the model would result in the lowest sum of squared errors $(SSE)$. Use the following method of computing SSE: `np.sum((y-model.predict(X))**2)`\n",
    "\n",
    "- Use your function to determine the best $k=2$ features to include in the model. Clearly indicate which feature was added in each stage via a print statement. \n",
    "\n",
    "**Note**: The point of this exercise is to see if you can implement **foward_select** yourself.  You may of course use canned routines like statmodels OLS, but you may not call any Python method that explicitly performs forward selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding  X1  feature.\n",
      "11948.951823657711\n",
      "Adding  X2  feature.\n",
      "4725.290770569185\n",
      "Adding  X3  feature.\n",
      "45646.598160522975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['X1', 'X2']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward_select(df, resp_str=\"Y\", maxk=2):\n",
    "    # Code Here\n",
    "    initial_features = df.columns[1:4].tolist()\n",
    "    desired_features = []\n",
    "    min = float('inf')\n",
    "    min2 = float('inf')\n",
    "    for i in initial_features:\n",
    "        print(\"Adding \" , i , \" feature.\")\n",
    "        X = df[[i,i,i]]\n",
    "        X = sm.add_constant(X)\n",
    "        SSE = np.sum((y-model.predict(X))**2)\n",
    "        print (SSE)\n",
    "        if (SSE < min2):\n",
    "            desired_features.append(i)\n",
    "        min2 = min\n",
    "        min = SSE\n",
    "    return desired_features\n",
    "    \n",
    "forward_select(dfBo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: Write down the reduced multiple linear regression model, including estimated parameters, obtained by your forward selection process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const    11.848212\n",
      "X1        4.228244\n",
      "X2        7.436110\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felipelima/opt/anaconda3/lib/python3.8/site-packages/scipy/stats/stats.py:1603: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.954</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   72.14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 09 Dec 2021</td> <th>  Prob (F-statistic):</th> <td>2.13e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:47:41</td>     <th>  Log-Likelihood:    </th> <td> -33.497</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    10</td>      <th>  AIC:               </th> <td>   72.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     7</td>      <th>  BIC:               </th> <td>   73.90</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   11.8482</td> <td>    6.765</td> <td>    1.751</td> <td> 0.123</td> <td>   -4.148</td> <td>   27.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>    <td>    4.2282</td> <td>    1.153</td> <td>    3.667</td> <td> 0.008</td> <td>    1.502</td> <td>    6.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>    <td>    7.4361</td> <td>    1.806</td> <td>    4.117</td> <td> 0.004</td> <td>    3.165</td> <td>   11.707</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.675</td> <th>  Durbin-Watson:     </th> <td>   2.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.263</td> <th>  Jarque-Bera (JB):  </th> <td>   0.636</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.583</td> <th>  Prob(JB):          </th> <td>   0.728</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.407</td> <th>  Cond. No.          </th> <td>    28.4</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.954\n",
       "Model:                            OLS   Adj. R-squared:                  0.941\n",
       "Method:                 Least Squares   F-statistic:                     72.14\n",
       "Date:                Thu, 09 Dec 2021   Prob (F-statistic):           2.13e-05\n",
       "Time:                        21:47:41   Log-Likelihood:                -33.497\n",
       "No. Observations:                  10   AIC:                             72.99\n",
       "Df Residuals:                       7   BIC:                             73.90\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         11.8482      6.765      1.751      0.123      -4.148      27.845\n",
       "X1             4.2282      1.153      3.667      0.008       1.502       6.955\n",
       "X2             7.4361      1.806      4.117      0.004       3.165      11.707\n",
       "==============================================================================\n",
       "Omnibus:                        2.675   Durbin-Watson:                   2.012\n",
       "Prob(Omnibus):                  0.263   Jarque-Bera (JB):                0.636\n",
       "Skew:                          -0.583   Prob(JB):                        0.728\n",
       "Kurtosis:                       3.407   Cond. No.                         28.4\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code Here\n",
    "X2 = dfBo[[\"X1\", \"X2\"]]\n",
    "X2 = sm.add_constant(X2)\n",
    "y2 = dfBo[\"Y\"]\n",
    "\n",
    "model2 = sm.OLS(y2, X2).fit()\n",
    "\n",
    "print(model2.params)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "$$\n",
    "\\texttt{Y} = 11.848212 + 4.228244 \\times \\texttt{X1} + 7.436110 \\times \\texttt{X2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part G:** \n",
    "\n",
    "- Compare or contrast the findings of your Forward Select algorithm from **Part E** with the p-values for each feature that were given in the full model summary. \n",
    "\n",
    "- Are the seemingly two best features the same?\n",
    "\n",
    "- How does the $R^2$ value of the full model compare to the $R^2$ value of the reduced model?\n",
    "\n",
    "- How does the $F$-statistic value of the full model compare to the $F$-statistic value of the reduced model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "X1 and X2 had the smallest p-values and were the two best features according to the forward selection.\n",
    "\n",
    "$R^2$ of the reduced model is smaller than $R^2$ value of the full model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Problem 2 - ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set includes ratings from 8 different individuals for 10 different types of jelly beans. The ratings are values that range from 1 to 10 with a 10 indicating the best positive rating and a 1 indicating the worst negative rating.\n",
    "\n",
    "As you examine the data, a booming voice from the sky instructs you to analyze the data to answer the following key question:\n",
    "$\\color{blue}{\\text{\"Is there a statistically significant difference between the mean ratings given to the ten different flavors of jelly beans?\"}}$\n",
    "\n",
    "**Part A:** Convert the `JellyBeanRatings` data set to a Pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "JellyBeanRatings = {\"Buttered Popcorn\": [5, 7, 8, 6, 6, 7, 9, 7], \"Caramel Corn\": [5, 4, 5, 3, 5, 4, 4, 3], \"Cappucino\": [4, 2, 4, 2, 4, 6, 7, 4], \"Pomegranate\": [3, 6, 6, 5, 4, 6, 5, 4],\n",
    "                    \"Lemon\": [1, 7, 3, 4, 2, 6, 4, 4], \"Pink Grapefruit\": [3, 1, 6, 3, 2, 4, 5, 2], \"Green Apple\": [4, 4, 1, 3, 4, 2, 3, 2], \"Orange Sherbet\": [9, 6, 3, 3, 4, 3, 4, 3], \"A&W Root Beer\": [ 7,  8,  7,  7,  7, 10, 10,  9],\n",
    "                    \"Sizzling Cinnamon\": [1, 6, 1, 4, 3, 4, 4, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Buttered Popcorn</th>\n",
       "      <th>Caramel Corn</th>\n",
       "      <th>Cappucino</th>\n",
       "      <th>Pomegranate</th>\n",
       "      <th>Lemon</th>\n",
       "      <th>Pink Grapefruit</th>\n",
       "      <th>Green Apple</th>\n",
       "      <th>Orange Sherbet</th>\n",
       "      <th>A&amp;W Root Beer</th>\n",
       "      <th>Sizzling Cinnamon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Buttered Popcorn  Caramel Corn  Cappucino  Pomegranate  Lemon  \\\n",
       "0                 5             5          4            3      1   \n",
       "1                 7             4          2            6      7   \n",
       "2                 8             5          4            6      3   \n",
       "3                 6             3          2            5      4   \n",
       "4                 6             5          4            4      2   \n",
       "5                 7             4          6            6      6   \n",
       "6                 9             4          7            5      4   \n",
       "7                 7             3          4            4      4   \n",
       "\n",
       "   Pink Grapefruit  Green Apple  Orange Sherbet  A&W Root Beer  \\\n",
       "0                3            4               9              7   \n",
       "1                1            4               6              8   \n",
       "2                6            1               3              7   \n",
       "3                3            3               3              7   \n",
       "4                2            4               4              7   \n",
       "5                4            2               3             10   \n",
       "6                5            3               4             10   \n",
       "7                2            2               3              9   \n",
       "\n",
       "   Sizzling Cinnamon  \n",
       "0                  1  \n",
       "1                  6  \n",
       "2                  1  \n",
       "3                  4  \n",
       "4                  3  \n",
       "5                  4  \n",
       "6                  4  \n",
       "7                  3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code Here\n",
    "dfJb = pd.DataFrame(JellyBeanRatings)\n",
    "\n",
    "dfJb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B:** In the remainder of this problem, you will perform some hypothesis tests to examine whether these data suggest there are significant differences in the mean ratings of the different jelly bean flavors. Pick a level of significance for these experiments, and explain what that significance level means. \"Because we used it a lot in class\" is ***not*** a good reason. Instead think of type 1 and type 2 errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "\n",
    "I decided to pick a $\\alpha = 0.05$ significance level because it is the risk I am willing to take to commit a type 1 error; rejecting $H_0$, in favor of $H_1$ when I shouldnâ€™t have. The significance level means I am willing to take a 5% risk of saying the mean ratings for the types of jelly bean are not equal when they really are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C:** Perform an **Analysis of Variance hypothesis test** in order to determine if there is evidence that there is _some_ difference among the mean ratings given to these 10 jelly bean flavors. Clearly state your null and alternative hypothesis, and use the significance level identified in **Part B**. You must show **all** calculations **by hand** (and may of course use Python as a calculator, and to compute values from a distribution using the appropriate percent-point-function (ppf) or cumulative distribution function (cdf)).\n",
    "\n",
    "In addition to showing the code for your calculations, make comments **in Markdown** explaining what you are doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "$H_0$: There is no difference in mean ratings between the mean ratings given to the ten different flavors of jelly beans\n",
    "\n",
    "$H_1$: There is a statistically significant difference between the mean ratings given to the ten different flavors of jelly beans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D:** Perform a **t hypothesis test** to determine if there is evidence supporting the claim that A&W Root Beer Jelly Bellies have a higher mean rating than Green Apple Jelly Bellies. Use the significance level you identified in **Part B**. Clearly state your null and alternative hypotheses, your conclusions, and show all work. Again, you may not use any canned t-test function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "$H_0$: There is no difference in mean ratings between the two jelly bean types.\n",
    "\n",
    "$H_1$: A&W Root Beer Jelly Bellies have a higher mean rating than Green Apple Jelly Bellies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=array([8.42410335]), pvalue=array([7.46799747e-07]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code Here\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "jb1 = dfJb[[\"A&W Root Beer\"]]\n",
    "jb2 = dfJb[[\"Green Apple\"]]\n",
    "\n",
    "ttest_ind(jb1,jb2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E:** Do your results from Parts C and D agree with one another? If they agree, explain how they are in agreement in _words_. If they do not agree, explain why you think they do not agree.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
